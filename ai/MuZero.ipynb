{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$UCB = Q(s,a) + \\left(c \\cdot P(s,a) \\cdot \\sqrt{\\frac{lnN} {1+n}}\\right)$\n",
    "\n",
    "$Q = \\text{value}$ <br>\n",
    "$P = \\text{policy}$ <br>\n",
    "$N = \\text{parent node visits}$ <br>\n",
    "$n = \\text{action visits}$ <br>\n",
    "$c = \\text{exploration hyperparameter}$ <br>\n",
    "$a = \\text{current action}$ <br>\n",
    "$s = \\text{current state}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$pUCT = Q(s,a) + P(s,a) \\cdot \\frac{\\sqrt{\\sum_{b}{N(s,b)}}} {1+N(s,a)} \\left(c_{1} + \\text{log} \\left(\\frac{\\sum_{b}{N(s,b)+c_{2}+1}} {c_{2}}\\right) \\right)$\n",
    "\n",
    "$Q = \\text{value}$ <br>\n",
    "$P = \\text{policy}$ <br>\n",
    "$N = \\text{visit count}$ <br>\n",
    "$c_{1} = \\text{exploration hyperparameter}$ <br>\n",
    "$c_{2} = \\text{exploration hyperparameter}$ <br>\n",
    "$a = \\text{current action}$ <br>\n",
    "$b = \\text{avaliable actions}$ <br>\n",
    "$s = \\text{current state}$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$P(s,a) = (1-\\epsilon)p_{a} + \\epsilon \\eta_{a}$\n",
    "\n",
    "$\\epsilon = \\text{exploration factor}$ <br>\n",
    "$\\eta = \\text{dirchlet distribution}$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$\\eta \\sim \\text{Dir}(\\alpha)$\n",
    "\n",
    "$\\alpha = \\text{vector of repetitions}$\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$\\overline{\\rm Q}(s^{k-1},a^{k}) = \\frac{Q(s^{k-1},a^{k})-\\text{min}_{s,a \\epsilon Tree}Q(s,a)}{\\text{max}_{s,a \\epsilon Tree}Q(s,a)-\\text{min}_{s,a \\epsilon Tree}Q(s,a)}$\n",
    "\n",
    "$Q = \\text{value}$ <br>\n",
    "$s = \\text{state}$ <br>\n",
    "$a = \\text{action}$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$G^{k} = \\sum^{l-1-k}_{\\tau=0}{\\gamma^{\\tau}r_{k+1+\\tau}+\\gamma^{l-k}v^{l}}$\n",
    "\n",
    "$\\gamma = \\text{gamma discount}$ <br>\n",
    "$r = \\text{reward}$ <br>\n",
    "$v = \\text{value}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$Q(s^{k-1},a^{k}):=\\frac{N(s^{k-1},a^{k}) \\cdot Q(s^{k-1},a^{k})+G^{k}}{N(s^{k-1},a^{k})+1}$\n",
    "\n",
    "$Q = \\text{value}$ <br>\n",
    "$N = \\text{visit count}$ <br>\n",
    "$G = \\text{generalized backup}$ <br>\n",
    "$s = \\text{state}$ <br>\n",
    "$a = \\text{action}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$h_{\\theta}(s) = s_{h}$\n",
    "\n",
    "$s = \\text{current state}$ <br>\n",
    "$s_{h} = \\text{hidden state representation}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$f_{\\theta}(s^{k}) = p^{k},v^{k}$\n",
    "\n",
    "$p = \\text{policy}$ <br>\n",
    "$v = \\text{value}$ <br>\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$g_{\\theta}(s_{h}^{k-1},a^{k}) = r^{k},s_{h}^{k}$\n",
    "\n",
    "$a = \\text{current action}$ <br>\n",
    "$s_{h} = \\text{hidden state representation}$ <br>\n",
    "$r = \\text{reward}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class MCTS:\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search algorithm used to search game tree for the best move\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        #prediction,\n",
    "        #dynamics,\n",
    "        user = None,\n",
    "        c1 = 1.25,\n",
    "        c2 = 19652,\n",
    "        d_a = .3,\n",
    "        e_f = .25,\n",
    "        g_d = 1.,\n",
    "        temp = 1.,\n",
    "        max_depth = float('inf')\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Input: prediction - NN used to predict p, v values\n",
    "               dynamics - NN used to predict the next states hidden values and the reward\n",
    "               user - integer representing which user the agent is (default = None) [OPTIONAL]\n",
    "               c1 - float representing a search hyperparameter (default = 1.25) [OPTIONAL]\n",
    "               c2 - float representing a search hyperparameter (default = 19652) [OPTIONAL]\n",
    "               d_a = float representing the dirichlet alpha you wish to use (default = 0.3) [OPTIONAL]\n",
    "               e_f = float representing the exploration fraction you wish to use with dirichlet alpha noise (default = 0.25) [OPTIONAL]\n",
    "               g_d = float representing the gamma discount to apply to v_k+1 when backpropagating tree (default = 1) [OPTIONAL]\n",
    "               max_depth - integer representing the max allowable depth to search tree (default = inf) [OPTIONAL]\n",
    "        Description: MCTS initail variables\n",
    "        Output: None\n",
    "        \"\"\"\n",
    "        self.tree = {} #Game tree\n",
    "        self.l = 0 #Last node depth\n",
    "        self.max_depth = max_depth #Max allowable depth\n",
    "        self.c1 = c1 #Exploration hyper parameter 1\n",
    "        self.c2 = c2 #Exploration hyper parameter 2\n",
    "        self.d_a = d_a #Dirichlet alpha\n",
    "        self.e_f = e_f #Exploration fraction\n",
    "        self.g_d = g_d #Gamma discount\n",
    "        self.Q_max = 1 #Max value\n",
    "        self.Q_min = -1 #Min value\n",
    "        self.v_l = 0 #Last depth value\n",
    "        #self.g = dynamics #Model used for dynamics\n",
    "        #self.f = prediction #Model used for prediction\n",
    "\n",
    "    class Node:\n",
    "        \"\"\"\n",
    "        Node for each state in the game tree\n",
    "        \"\"\"\n",
    "        def __init__(self):\n",
    "            \"\"\"\n",
    "            Input: None\n",
    "            Description: Node initail variables\n",
    "            Output: None\n",
    "            \"\"\"\n",
    "            self.N = 0 #Visits\n",
    "            self.Q = 0 #Value\n",
    "            self.R = 0 #Reward\n",
    "            self.S = None #State\n",
    "            self.P = None #Policy\n",
    "            self.n_s = []\n",
    "            \n",
    "    def state_hash(self, s):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "        Description: generate unique hash of the supplied hidden state\n",
    "        Output: integer representing unique hash of the supplied hidden state\n",
    "        \"\"\"\n",
    "        result = hash(str(s))\n",
    "        return result\n",
    "    \n",
    "    def dirichlet_noise(self, p):\n",
    "        \"\"\"\n",
    "        Input: p - list of floats [0-1] representing action probability distrabution\n",
    "        Description: add dirichlet noise to probability distrabution\n",
    "        Output: list of floats [0-1] representing action probability with added noise\n",
    "        \"\"\"\n",
    "        d = np.random.dirichlet([self.d_a] * len(p))\n",
    "        return (d * self.e_f) + ((1 - self.e_f) * p)\n",
    "    \n",
    "    def pUCT(self, s):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "        Description: return best action state using polynomial upper confidence trees\n",
    "        Output: integer containing the best action\n",
    "        \"\"\"\n",
    "        p_visits = sum([self.tree[(s, b)].N for b in range(4)]) #Sum of all potential nodes\n",
    "        #p_visits = sum([self.tree[(s, b)].N for b in range(self.f.action_space)]) #Sum of all potential nodes\n",
    "        u_bank = {}\n",
    "        #for a in range(self.f.action_space):\n",
    "        for a in range(4):\n",
    "            U = self.tree[(s, a)].P * ((p_visits**(0.5))/(1+self.tree[(s, a)].N)) #First part of exploration\n",
    "            U *= self.c1 + (math.log((p_visits+(4*self.c2)+4)/self.c2)) #Second part of exploration\n",
    "            #U *= self.c1 + (math.log((p_visits + (self.f.action_space * self.c2) + self.f.action_space) / self.c2)) #Second part of exploration\n",
    "            Q_n = (self.tree[(s, a)].Q - self.Q_min) / (self.Q_max - self.Q_min) #Normalized value\n",
    "            u_bank[a] = Q_n + U\n",
    "        a_bank = [k for k,v in u_bank.items() if v == max(u_bank.values())]\n",
    "        return random.choice(a_bank)\n",
    "        \n",
    "    def search(self, s, a = None, train = False):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "               a - integer representing which action is being performed (default = None) [OPTIONAL]\n",
    "               train - boolean representing if search is being used in training mode (default = False) [OPTIONAL]\n",
    "        Description: Search the task action tree using upper confidence value\n",
    "        Output: predicted value\n",
    "        \"\"\"\n",
    "        s_hash = self.state_hash(s) #Create hash of state [sk-1] for game tree\n",
    "        if (s_hash, a) not in self.tree:\n",
    "            self.tree[(s_hash, a)] = self.Node() #Initialize new game tree node\n",
    "        if a is not None:\n",
    "            if self.tree[(s_hash, a)].S is None:\n",
    "                r_k, s = self.g(s, a) #Reward and state prediction using dynamics function\n",
    "                self.tree[(s_hash, a)].S = s\n",
    "                self.tree[(s_hash, a)].R = r_k\n",
    "            else:\n",
    "                s = self.tree[(s_hash, a)].S\n",
    "        sk_hash = self.state_hash(s) #Create hash of state [sk] for game tree\n",
    "        if self.tree[(s_hash, a)].N == 0:\n",
    "            #EXPANSION ---\n",
    "            v_k, p = self.f(s) #Value and policy prediction using prediction function\n",
    "            if a is None and train == True:\n",
    "                p = self.dirichlet_noise(p) #Add dirichlet noise to p @ s0\n",
    "            self.tree[(s_hash, a)].Q = v_k\n",
    "            self.v_l = self.tree[(s_hash, a)].Q\n",
    "            for a_k, p_a in enumerate(p):\n",
    "                self.tree[(sk_hash, a_k)] = self.Node()\n",
    "                self.tree[(sk_hash, a_k)].P = p_a\n",
    "                self.tree[(s_hash, a)].n_s.append((sk_hash, a_k))\n",
    "        elif self.l < self.max_depth:\n",
    "            a_k = self.pUCT(sk_hash) #Find best action to perform @ [sk]\n",
    "            k = self.l\n",
    "            self.l += 1\n",
    "            #BACKUP ---\n",
    "            G_1, r_1 = self.search(s, a_k) #Go level deeper\n",
    "            if (self.l - k - 1) > 0:\n",
    "                G_k = ((self.g_d ** (self.l - k - 1)) * r_1) + ((self.g_d ** (self.l - k)) * self.v_l)\n",
    "                G_k += G_1\n",
    "            else:\n",
    "                G_k = 0\n",
    "            self.tree[(s_hash, a)].Q = ((self.tree[(s_hash, a)].N * self.tree[(s_hash, a)].Q) + G_k) / (self.tree[(s_hash, a)].N + 1) #Updated value\n",
    "        if self.tree[(s_hash, a)].Q < self.Q_min:\n",
    "            self.Q_min = self.tree[(s_hash, a)].Q\n",
    "        if self.tree[(s_hash, a)].Q > self.Q_max:\n",
    "            self.Q_max = self.tree[(s_hash, a)].Q\n",
    "        if 'G_k' not in locals():\n",
    "            G_k = 0\n",
    "        self.tree[(s_hash, a)].N += 1\n",
    "        return G_k, -self.tree[(s_hash, a)].R\n",
    "    \n",
    "    def g(self,s,a):\n",
    "        \"\"\"\n",
    "        TEMPORARY DYNAMICS MODEL FOR TESTING SEARCH\n",
    "        \"\"\"\n",
    "        return 0, s*random.choice([.1, .2, .11, .26, .4, .7, .6, .3, .5, .66, .8, .14, .32, .17])\n",
    "    \n",
    "    def f(self, s):\n",
    "        \"\"\"\n",
    "        TEMPORARY PREDICTION MODEL FOR TESTING SEARCH\n",
    "        \"\"\"\n",
    "        return random.choice([-1, 0, 1]), np.random.rand(4)\n",
    "    \n",
    "    def log(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MCTS(s_{t},\\mu_{\\theta})=v_{t},\\pi_{t}$\n",
    "\n",
    "$s = \\text{current state}$ <br>\n",
    "$v = \\text{state value}$ <br>\n",
    "$\\pi = \\text{action policy}$ <br>\n",
    "$\\mu_{\\theta} = \\text{neural networks}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$\\mu_{\\theta} = h_{\\theta}(s),f_{\\theta}(s^{k}),g_{\\theta}(s_{h}^{k-1},a^{k})$\n",
    "\n",
    "$\\mu_{\\theta} = \\text{neural networks}$ <br>\n",
    "$h_{\\theta} = \\text{representation}$ <br>\n",
    "$f_{\\theta} = \\text{predictions}$ <br>\n",
    "$g_{\\theta} = \\text{dynamics}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$\\pi=\\frac{N(a)^{1/\\tau}}{\\sum_{b}{N(b)^{1/\\tau}}}$\n",
    "\n",
    "$N = \\text{visit count}$ <br>\n",
    "$\\tau = \\text{tempature}$ <br>\n",
    "$a = \\text{current action}$ <br>\n",
    "$b = \\text{avaliable actions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20833333333333334, 0.2916666666666667, 0.375, 0.125]\n"
     ]
    }
   ],
   "source": [
    "temp = 1\n",
    "num_sims = 25\n",
    "s = np.random.rand(3,2)\n",
    "\n",
    "search = MCTS()\n",
    "for x in range(num_sims):\n",
    "    search.l = 0\n",
    "    search.v_l = 0\n",
    "    search.search(s)\n",
    "\n",
    "s_hash = search.state_hash(s)\n",
    "counts = {a: search.tree[(s_hash,a)].N for a in range(4)}\n",
    "\n",
    "if temp == 0:\n",
    "    a_bank = [k for k,v in counts.items() if v == max(counts.values())]\n",
    "    a = random.choice(a_bank)\n",
    "    probs = [0] * len(counts)\n",
    "    probs[a] = 1\n",
    "else:\n",
    "    c_s = sum(c ** (1./temp) for c in counts.values())\n",
    "    probs = [(x ** (1./temp)) / c_s for x in counts.values()]\n",
    "    \n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1925\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1927\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-deddfd447a04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#Display network graph -----------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m nx.draw(\n",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\networkx\\drawing\\nx_pydot.py\u001b[0m in \u001b[0;36mgraphviz_layout\u001b[1;34m(G, prog, root)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mwrapper\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpydot_layout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpydot_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\networkx\\drawing\\nx_pydot.py\u001b[0m in \u001b[0;36mpydot_layout\u001b[1;34m(G, prog, root)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# List of low-level bytes comprising a string in the dot language converted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;31m# from the passed graph with the passed external GraphViz command.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mD_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;31m# Unique string decoded from these bytes with the preferred locale encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(f, prog, encoding)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                 \u001b[1;34m\"\"\"Refer to docstring of method `create`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m                 return self.create(\n\u001b[1;32m-> 1734\u001b[1;33m                     format=f, prog=prog, encoding=encoding)\n\u001b[0m\u001b[0;32m   1735\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'create_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben\\documents\\virtualenv\\mrp\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1931\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1932\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1933\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1934\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pydot\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "G = nx.Graph()\n",
    "for s in search.tree:\n",
    "    for a in search.tree[s].n_s:\n",
    "        G.add_edge(s,a)\n",
    "        \n",
    "pos = graphviz_layout(G, prog='dot')\n",
    "#Display network graph -----------------------------\n",
    "nx.draw(\n",
    "    G, #Graph nodes & connections\n",
    "    pos, #Position of graph\n",
    "    with_labels=True #Labels on nodes\n",
    ")\n",
    "plt.rcParams['figure.figsize'] = [40, 40] #Resize graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
