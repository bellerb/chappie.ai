{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "class MCTS:\n",
    "    \"\"\"\n",
    "    Monte Carlo Tree Search algorithm used to search game tree for the best move\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        #prediction,\n",
    "        #dynamics,\n",
    "        user = None,\n",
    "        c1 = 1.25,\n",
    "        c2 = 19652,\n",
    "        d_a = .3,\n",
    "        e_f = .25,\n",
    "        g_d = 1.,\n",
    "        temp = 1.,\n",
    "        Q_max = 1,\n",
    "        Q_min = -1,\n",
    "        max_depth = float('inf')\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Input: prediction - NN used to predict p, v values\n",
    "               dynamics - NN used to predict the next states hidden values and the reward\n",
    "               user - integer representing which user the agent is (default = None) [OPTIONAL]\n",
    "               c1 - float representing a search hyperparameter (default = 1.25) [OPTIONAL]\n",
    "               c2 - float representing a search hyperparameter (default = 19652) [OPTIONAL]\n",
    "               d_a = float representing the dirichlet alpha you wish to use (default = 0.3) [OPTIONAL]\n",
    "               e_f = float representing the exploration fraction you wish to use with dirichlet alpha noise (default = 0.25) [OPTIONAL]\n",
    "               g_d = float representing the gamma discount to apply to v_k+1 when backpropagating tree (default = 1) [OPTIONAL]\n",
    "               Q_max = float representing the max value (default = 1) [OPTIONAL]\n",
    "               Q_min = float representing the min value (default = -1) [OPTIONAL]\n",
    "               max_depth - integer representing the max allowable depth to search tree (default = inf) [OPTIONAL]\n",
    "        Description: MCTS initail variables\n",
    "        Output: None\n",
    "        \"\"\"\n",
    "        self.tree = {} #Game tree\n",
    "        self.depth = 0 #Curent node depth\n",
    "        self.max_depth = max_depth #Max allowable depth\n",
    "        self.c1 = c1 #Exploration hyper parameter 1\n",
    "        self.c2 = c2 #Exploration hyper parameter 2\n",
    "        self.d_a = d_a #Dirichlet alpha\n",
    "        self.e_f = e_f #Exploration fraction\n",
    "        self.g_d = g_d #Gamma discount\n",
    "        self.Q_max = Q_max #Max value\n",
    "        self.Q_min = Q_min #Min value\n",
    "        #self.g = dynamics #Model used for dynamics\n",
    "        #self.f = prediction #Model used for prediction\n",
    "\n",
    "    class Node:\n",
    "        \"\"\"\n",
    "        Node for each state in the game tree\n",
    "        \"\"\"\n",
    "        def __init__(self):\n",
    "            \"\"\"\n",
    "            Input: None\n",
    "            Description: Node initail variables\n",
    "            Output: None\n",
    "            \"\"\"\n",
    "            self.N = 0 #Visits\n",
    "            self.Q = 0 #Value\n",
    "            self.R = 0 #Reward\n",
    "            self.P = None #Policy\n",
    "            \n",
    "    def state_hash(self, s):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "        Description: generate unique hash of the supplied hidden state\n",
    "        Output: integer representing unique hash of the supplied hidden state\n",
    "        \"\"\"\n",
    "        result = hash(str(s))\n",
    "        return result\n",
    "    \n",
    "    def dirichlet_noise(self, p):\n",
    "        \"\"\"\n",
    "        Input: p - list of floats [0-1] representing action probability distrabution\n",
    "        Description: add dirichlet noise to probability distrabution\n",
    "        Output: list of floats [0-1] representing action probability with added noise\n",
    "        \"\"\"\n",
    "        d = np.random.dirichlet([self.d_a] * len(p))\n",
    "        return (d * self.e_f) + ((1 - self.e_f) * p)\n",
    "    \n",
    "    def pUCT(self, s):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "        Description: return best action state using polynomial upper confidence trees\n",
    "        Output: integer containing the best action\n",
    "        \"\"\"\n",
    "        p_visits = sum([self.tree[(s, b)].N for b in range(4)]) #Sum of all potential nodes\n",
    "        #p_visits = sum([self.tree[(s, b)].N for b in range(self.f.action_space)]) #Sum of all potential nodes\n",
    "        u_bank = {}\n",
    "        #for a in range(self.f.action_space):\n",
    "        for a in range(4):\n",
    "            U = self.tree[(s, a)].P * ((p_visits**(0.5))/(1+self.tree[(s, a)].N)) #First part of exploration\n",
    "            U *= self.c1 + (math.log((p_visits+(4*self.c2)+4)/self.c2)) #Second part of exploration\n",
    "            #U *= self.c1 + (math.log((p_visits + (self.f.action_space * self.c2) + self.f.action_space) / self.c2)) #Second part of exploration\n",
    "            Q_n = (self.tree[(s, a)].Q - self.Q_min) / (self.Q_max - self.Q_min) #Normalized value\n",
    "            u_bank[a] = Q_n + U\n",
    "        a_bank = [k for k,v in u_bank.items() if v == max(u_bank.values())]\n",
    "        return random.choice(a_bank)\n",
    "        \n",
    "    def search(self, s, a = None, train = False):\n",
    "        \"\"\"\n",
    "        Input: s - tensor representing hidden state of task\n",
    "               a - integer representing which action is being performed (default = None) [OPTIONAL]\n",
    "               train - boolean representing if search is being used in training mode (default = False) [OPTIONAL]\n",
    "        Description: Search the task action tree using upper confidence value\n",
    "        Output: predicted value\n",
    "        \"\"\"\n",
    "        s_hash = self.state_hash(s) #Create hash of state [sk-1] for game tree\n",
    "        if (s_hash, a) not in self.tree:\n",
    "            self.tree[(s_hash, a)] = self.Node() #Initialize new game tree node\n",
    "        if a is not None:\n",
    "            r_k, s = self.g(s, a) #Reward and state prediction using dynamics function\n",
    "            self.tree[(s_hash, a)].R = r_k\n",
    "        sk_hash = self.state_hash(s) #Create hash of state [sk] for game tree\n",
    "        if self.tree[(s_hash, a)].N == 0:\n",
    "            v_k, p = self.f(s) #Value and policy prediction using prediction function\n",
    "            if a is None and train == True:\n",
    "                p = self.dirichlet_noise(p) #Add dirichlet noise to p @ s0\n",
    "            self.tree[(s_hash, a)].Q = v_k\n",
    "            #EXPANSION ---\n",
    "            for a_k, p_a in enumerate(p):\n",
    "                self.tree[(sk_hash, a_k)] = self.Node()\n",
    "                self.tree[(sk_hash, a_k)].P = p_a\n",
    "            self.tree[(s_hash, a)].N += 1\n",
    "            return self.tree[(s_hash, a)].Q\n",
    "        a_k = self.pUCT(sk_hash) #Find best action to perform @ [sk]\n",
    "        if self.depth < self.max_depth:\n",
    "            self.depth += 1\n",
    "            #BACKUP ---\n",
    "            g = self.tree[(s_hash, a)].R + self.g_d * self.search(s, a_k) #Discounted value at current node\n",
    "            q_m = (self.tree[(s_hash, a)].N * self.tree[(s_hash, a)].Q + g) / self.tree[(s_hash, a)].N #Mean value\n",
    "            self.tree[(s_hash, a)].Q = q_m\n",
    "        self.tree[(s_hash, a)].N += 1\n",
    "        return self.tree[(s_hash, a)].Q\n",
    "    \n",
    "    def g(self,s,a):\n",
    "        \"\"\"\n",
    "        TEMPORARY DYNAMICS MODEL FOR TESTING SEARCH\n",
    "        \"\"\"\n",
    "        return 1, s*0.1\n",
    "    \n",
    "    def f(self, s):\n",
    "        \"\"\"\n",
    "        TEMPORARY PREDICTION MODEL FOR TESTING SEARCH\n",
    "        \"\"\"\n",
    "        return random.choice([-1, 0, 1]), np.random.rand(4)\n",
    "    \n",
    "    def log(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 4, 3: 18}\n",
      "[0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "num_sims = 25\n",
    "s = np.random.rand(3,2)\n",
    "\n",
    "search = MCTS()\n",
    "for x in range(num_sims):\n",
    "    search.depth = 0\n",
    "    search.search(s)\n",
    "\n",
    "s_hash = search.state_hash(s)\n",
    "counts = {a: search.tree[(s_hash,a)].N for a in range(4)}\n",
    "\n",
    "if temp == 0:\n",
    "    a_bank = [k for k,v in counts.items() if v == max(counts.values())]\n",
    "    a = random.choice(a_bank)\n",
    "    probs = [0] * len(counts)\n",
    "    probs[a] = 1\n",
    "else:\n",
    "    c_s = sum(counts.values())\n",
    "    print(c_s, 1./temp)\n",
    "    probs = [(x ** (1./temp)) / c_s for x in counts.values()]\n",
    "    \n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2444e6308ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Connecting of nodes -------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Current Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PD-Framing'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PD-Press'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Wrapping - PD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Released-FrameP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Released-SashP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Custom'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Hardware-Frame-Tilt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Hardware-Sash-Tilt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Current Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mg_flow_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Current Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mg_flow_hold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Next Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PD-Framing'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'PD-Press'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Wrapping - PD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Released-FrameP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Released-SashP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Custom'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Hardware-Frame-Tilt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Hardware-Sash-Tilt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Next Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flow' is not defined"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Connecting of nodes -------------------------------\n",
    "G = nx.Graph()\n",
    "for g in flow[~flow['Current Area'].isin(['PD-Framing','PD-Press','Wrapping - PD','Released-FrameP','Released-SashP','Custom','Hardware-Frame-Tilt','Hardware-Sash-Tilt'])]['Current Area'].unique():\n",
    "    g_flow_hold = flow[flow['Current Area']==g]\n",
    "    for n in g_flow_hold[~flow['Next Area'].isin(['PD-Framing','PD-Press','Wrapping - PD','Released-FrameP','Released-SashP','Custom','Hardware-Frame-Tilt','Hardware-Sash-Tilt'])]['Next Area'].unique():\n",
    "        G.add_edge(g, n, weight = 10)               \n",
    "#Formating of network graph ------------------------\n",
    "pos = nx.spring_layout(G, scale=10000, k=0.1/np.sqrt(G.order()), iterations=10000) #Space nodes for better visibility\n",
    "colours = []\n",
    "for node in G.nodes():\n",
    "    if 'Scheduled' in node:\n",
    "        colours.append('blue')\n",
    "    elif 'Packaging' in node:\n",
    "        colours.append('green')\n",
    "    else:\n",
    "        colours.append('red')\n",
    "#Display network graph -----------------------------\n",
    "nx.draw(\n",
    "    G, #Graph nodes & connections\n",
    "    pos, #Position of graph\n",
    "    node_color=colours, #Colour of nodes \n",
    "    with_labels=True #Labels on nodes\n",
    ")\n",
    "plt.rcParams['figure.figsize'] = [20, 3] #Resize graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
